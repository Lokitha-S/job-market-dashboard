# ğŸ“Š Automated Job Market Intelligence Dashboard

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://share.streamlit.io/) 
![Python](https://img.shields.io/badge/Python-3.9-blue)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-NeonDB-green)
![Status](https://img.shields.io/badge/Status-Live-success)

## ğŸš€ Project Overview
This project is an end-to-end **ETL (Extract, Transform, Load) pipeline** that tracks Python job market trends. It automatically scrapes job listings daily, stores them in a cloud database, and visualizes the data through an interactive dashboard.

**âœ¨ Key Features
Automated Data Extraction: A Python script runs automatically every 24 hours via GitHub Actions to scrape new job listings.

Cloud Data Persistence: Data is cleaned (Pandas) and stored securely in a PostgreSQL (Neon) database, preventing data loss on app restarts.

Interactive Dashboard: Built with Streamlit, featuring:

ğŸ“… Date Range Filtering

ğŸ” Keyword Search (e.g., "Backend", "Junior")

ğŸ“Š Interactive Charts (Plotly)

ğŸ“¥ CSV Data Export

Security: Uses environment variables and GitHub Secrets to protect database credentials.

ğŸ› ï¸ Tech Stack
Language: Python 3.9

Web Scraping: BeautifulSoup4, Requests

Data Manipulation: Pandas, NumPy

Database: PostgreSQL (hosted on Neon.tech), SQLAlchemy

Visualization: Streamlit, Plotly Express

DevOps/Automation: GitHub Actions (CI/CD), Streamlit Cloud

**ğŸ¤– Automation (GitHub Actions)
The scraping process is automated using a YAML workflow file located in .github/workflows/daily_scrape.yml.

Trigger: Scheduled Cron Job (Runs daily at 02:00 UTC).

Process: Sets up Python environment -> Installs dependencies -> Runs scraper.py -> Closes connection.

---

## ğŸ—ï¸ Architecture
The system follows a modern serverless architecture:

```mermaid
graph LR
    A["GitHub Actions<br>(Daily Automation)"] -->|Runs Scraper| B["Python Script<br>BeautifulSoup + Pandas"]
    B -->|ETL Process| C[("Neon PostgreSQL<br>Cloud Database")]
    D["Streamlit Cloud"] -->|Queries Data| C
    D -->|Displays| E["Interactive Web Dashboard"]

